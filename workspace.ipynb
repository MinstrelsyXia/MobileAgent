{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(image_path, prompt, ocr_detection, ocr_recognition, x, y):\n",
    "    text_data = []\n",
    "    coordinate = []\n",
    "    image = Image.open(image_path)\n",
    "    iw, ih = image.size\n",
    "    \n",
    "    image_full = cv2.imread(image_path)\n",
    "    det_result = ocr_detection(image_full)\n",
    "    det_result = det_result['polygons'] \n",
    "    for i in range(det_result.shape[0]):\n",
    "        pts = order_point(det_result[i])\n",
    "        image_crop = crop_image(image_full, pts)\n",
    "        result = ocr_recognition(image_crop)['text'][0]\n",
    "        \n",
    "        if result == prompt:\n",
    "            box = [int(e) for e in list(pts.reshape(-1))]\n",
    "            box = [box[0], box[1], box[4], box[5]]\n",
    "            \n",
    "            if calculate_size(box) > 0.05*iw*ih:\n",
    "                continue\n",
    "            \n",
    "            text_data.append([int(max(0, box[0]-10)*x/iw), int(max(0, box[1]-10)*y/ih), int(min(box[2]+10, iw)*x/iw), int(min(box[3]+10, ih)*y/ih)])\n",
    "            coordinate.append([int(max(0, box[0]-300)*x/iw), int(max(0, box[1]-400)*y/ih), int(min(box[2]+300, iw)*x/iw), int(min(box[3]+400, ih)*y/ih)])\n",
    "    \n",
    "    max_length = 0\n",
    "    if len(text_data) == 0:\n",
    "        for i in range(det_result.shape[0]):\n",
    "            pts = order_point(det_result[i])\n",
    "            image_crop = crop_image(image_full, pts)\n",
    "            result = ocr_recognition(image_crop)['text'][0]\n",
    "            \n",
    "            if len(result) < 0.3 * len(prompt):\n",
    "                continue\n",
    "            \n",
    "            if result in prompt:\n",
    "                now_length = len(result)\n",
    "            else:\n",
    "                now_length = longest_common_substring_length(result, prompt)\n",
    "            \n",
    "            if now_length > max_length and now_length >= 0.7*len(prompt):\n",
    "                max_length = now_length\n",
    "                box = [int(e) for e in list(pts.reshape(-1))]\n",
    "                box = [box[0], box[1], box[4], box[5]]\n",
    "                \n",
    "                text_data = [[int(max(0, box[0]-10)*x/iw), int(max(0, box[1]-10)*y/ih), int(min(box[2]+10, iw)*x/iw), int(min(box[3]+10, ih)*y/ih)]]\n",
    "                coordinate = [[int(max(0, box[0]-300)*x/iw), int(max(0, box[1]-400)*y/ih), int(min(box[2]+300, iw)*x/iw), int(min(box[3]+400, ih)*y/ih)]]\n",
    "\n",
    "        if len(prompt) <= 10:\n",
    "            if max_length >= 0.9*len(prompt):\n",
    "                return text_data, coordinate\n",
    "            else:\n",
    "                return [], []\n",
    "        elif (len(prompt) > 10) and (len(prompt) <= 20):\n",
    "            if max_length >= 0.8*len(prompt):\n",
    "                return text_data, coordinate\n",
    "            else:\n",
    "                return [], []\n",
    "        else:\n",
    "            if max_length >= 0.7*len(prompt):\n",
    "                return text_data, coordinate\n",
    "            else:\n",
    "                return [], []\n",
    "    \n",
    "    else:\n",
    "        return text_data, coordinate\n",
    "import os\n",
    "import clip\n",
    "import shutil\n",
    "import random\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from modelscope import snapshot_download\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from MobileAgent.api import inference_chat\n",
    "from MobileAgent.text_localization import ocr\n",
    "from MobileAgent.icon_localization import det\n",
    "from MobileAgent.crop import crop_for_clip, clip_for_icon\n",
    "from MobileAgent.chat import init_chat, add_response, print_status\n",
    "from MobileAgent.prompt import thought_prompt, action_prompt, format_prompt\n",
    "from MobileAgent.controller import get_size, get_screenshot, tap, type, slide, back, back_to_desktop\n",
    "image_ori = \"./screenshot/screenshot.png\"\n",
    "parameter = \n",
    "ocr_detection = pipeline(Tasks.ocr_detection, model='damo/cv_resnet18_ocr-detection-line-level_damo')\n",
    "ocr_recognition = pipeline(Tasks.ocr_recognition, model='damo/cv_convnextTiny_ocr-recognition-document_damo')\n",
    "in_coordinate, out_coordinate = ocr(image_ori, parameter, ocr_detection, ocr_recognition, iw, ih)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
